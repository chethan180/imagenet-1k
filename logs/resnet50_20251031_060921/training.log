2025-10-31 06:09:23,929 - INFO - Model info: {'total_parameters': 25557032, 'trainable_parameters': 25557032, 'model_size_mb': 97.49234008789062}
2025-10-31 06:09:34,012 - INFO - Step 0: {'train_loss_batch': 7.111979007720947, 'train_lr': 0.1, 'batch_time': 10.081496000289917, 'data_time': 5.207998752593994}
2025-10-31 06:12:18,434 - INFO - Step 100: {'train_loss_batch': 6.972568988800049, 'train_lr': 0.1, 'batch_time': 1.7277558156759432, 'data_time': 0.05236055827376866}
2025-10-31 06:15:04,309 - INFO - Step 200: {'train_loss_batch': 6.906253814697266, 'train_lr': 0.1, 'batch_time': 1.6934260337506954, 'data_time': 0.02669978616249502}
2025-10-31 06:17:48,653 - INFO - Step 300: {'train_loss_batch': 6.908353805541992, 'train_lr': 0.1, 'batch_time': 1.676817227835671, 'data_time': 0.018091651688382476}
2025-10-31 06:20:34,173 - INFO - Step 400: {'train_loss_batch': 6.914018630981445, 'train_lr': 0.1, 'batch_time': 1.6714257284292853, 'data_time': 0.013769694991837118}
2025-10-31 06:23:20,446 - INFO - Step 500: {'train_loss_batch': 6.88545036315918, 'train_lr': 0.1, 'batch_time': 1.6696899127579496, 'data_time': 0.011172560636630791}
2025-10-31 06:26:06,252 - INFO - Step 600: {'train_loss_batch': 6.804302215576172, 'train_lr': 0.1, 'batch_time': 1.667755293568438, 'data_time': 0.009449771954096891}
2025-10-31 06:28:52,325 - INFO - Step 700: {'train_loss_batch': 6.834394454956055, 'train_lr': 0.1, 'batch_time': 1.666752559482286, 'data_time': 0.00821242352865222}
2025-10-31 06:31:38,505 - INFO - Step 800: {'train_loss_batch': 6.631833076477051, 'train_lr': 0.1, 'batch_time': 1.6661335912983068, 'data_time': 0.007282127899474716}
2025-10-31 06:34:24,640 - INFO - Step 900: {'train_loss_batch': 6.8479533195495605, 'train_lr': 0.1, 'batch_time': 1.6656032415658863, 'data_time': 0.006561089832166191}
2025-10-31 06:37:08,998 - INFO - Step 1000: {'train_loss_batch': 6.452040672302246, 'train_lr': 0.1, 'batch_time': 1.6634028832038323, 'data_time': 0.005984356353332946}
2025-10-31 06:39:53,745 - INFO - Step 1100: {'train_loss_batch': 6.353535175323486, 'train_lr': 0.1, 'batch_time': 1.6619550716216513, 'data_time': 0.00551205564909475}
2025-10-31 06:42:39,714 - INFO - Step 1200: {'train_loss_batch': 6.304940223693848, 'train_lr': 0.1, 'batch_time': 1.6617669938108903, 'data_time': 0.00511993952933001}
2025-10-31 06:45:25,115 - INFO - Step 1300: {'train_loss_batch': 6.232202053070068, 'train_lr': 0.1, 'batch_time': 1.6611701740291283, 'data_time': 0.0047870642583613945}
2025-10-31 06:48:10,154 - INFO - Step 1400: {'train_loss_batch': 6.145053863525391, 'train_lr': 0.1, 'batch_time': 1.660400612366191, 'data_time': 0.00450227160184916}
2025-10-31 06:50:56,614 - INFO - Step 1500: {'train_loss_batch': 6.083698749542236, 'train_lr': 0.1, 'batch_time': 1.6606800678489528, 'data_time': 0.004254419274682763}
2025-10-31 06:53:43,223 - INFO - Step 1600: {'train_loss_batch': 5.935922622680664, 'train_lr': 0.1, 'batch_time': 1.661018028175883, 'data_time': 0.004038807304854098}
2025-10-31 06:56:28,946 - INFO - Step 1700: {'train_loss_batch': 5.926428318023682, 'train_lr': 0.1, 'batch_time': 1.6607951205453755, 'data_time': 0.0038481455280947588}
2025-10-31 06:59:15,508 - INFO - Step 1800: {'train_loss_batch': 6.01826810836792, 'train_lr': 0.1, 'batch_time': 1.6610632133377983, 'data_time': 0.0036799029996830647}
2025-10-31 07:02:01,731 - INFO - Step 1900: {'train_loss_batch': 5.73761510848999, 'train_lr': 0.1, 'batch_time': 1.6611243959855306, 'data_time': 0.0035292184208644685}
2025-10-31 07:04:46,349 - INFO - Step 2000: {'train_loss_batch': 5.709601402282715, 'train_lr': 0.1, 'batch_time': 1.6603772537759516, 'data_time': 0.003392737725566233}
2025-10-31 07:07:32,382 - INFO - Step 2100: {'train_loss_batch': 6.4370269775390625, 'train_lr': 0.1, 'batch_time': 1.6603751939458542, 'data_time': 0.003269422286921941}
2025-10-31 07:10:18,705 - INFO - Step 2200: {'train_loss_batch': 5.8206787109375, 'train_lr': 0.1, 'batch_time': 1.6605049678814623, 'data_time': 0.003155591432639871}
2025-10-31 07:13:04,545 - INFO - Step 2300: {'train_loss_batch': 5.681471824645996, 'train_lr': 0.1, 'batch_time': 1.6604133724700052, 'data_time': 0.003052193825268735}
2025-10-31 07:15:50,922 - INFO - Step 2400: {'train_loss_batch': 5.475764751434326, 'train_lr': 0.1, 'batch_time': 1.6605531317350617, 'data_time': 0.0029572967885187}
2025-10-31 07:18:37,510 - INFO - Step 2500: {'train_loss_batch': 5.576394081115723, 'train_lr': 0.1, 'batch_time': 1.660766016431257, 'data_time': 0.002897969440001099}
2025-10-31 07:20:22,183 - INFO - Step 0: {'epoch': 0, 'learning_rate': 0.020000800000000003, 'train_loss': 6.412045545143475, 'train_top1': 2.7748899217221137, 'train_top5': 8.652611301369863, 'train_precision': 2.904720896135699, 'train_recall': 2.735307207454258, 'train_f1': 2.263019735574086, 'val_loss': 7.965556249542236, 'val_top1': 0.128, 'val_top5': 0.392, 'val_precision': 0.13054830287206268, 'val_recall': 0.00016710182767624022, 'val_f1': 0.00033377642153291826}
2025-10-31 07:20:22,185 - INFO - Epoch 000 Summary - LR: 0.020001, Train Loss: 6.4120, Train Top1: 2.77%, Val Loss: 7.9656, Val Top1: 0.13%, Val Top5: 0.39%, Val F1: 0.00%, Val Precision: 0.13%, Val Recall: 0.00%
2025-10-31 07:20:22,756 - INFO - New best model saved with validation accuracy: 0.128%
2025-10-31 07:20:22,756 - INFO - Checkpoint saved: /home/ubuntu/imagenet-1k/checkpoints/resnet50_20251031_060921/checkpoint_epoch_001.pth
2025-10-31 07:20:28,236 - INFO - Step 2502: {'train_loss_batch': 6.2919769287109375, 'train_lr': 0.020000800000000003, 'batch_time': 5.478195905685425, 'data_time': 3.8209242820739746}
2025-10-31 07:23:14,820 - INFO - Step 2602: {'train_loss_batch': 5.763546943664551, 'train_lr': 0.020000800000000003, 'batch_time': 1.703594965509849, 'data_time': 0.03869797687719364}
2025-10-31 07:26:01,008 - INFO - Step 2702: {'train_loss_batch': 5.271365642547607, 'train_lr': 0.020000800000000003, 'batch_time': 1.6828390994475255, 'data_time': 0.01983887164746944}
2025-10-31 07:28:47,265 - INFO - Step 2802: {'train_loss_batch': 5.231070518493652, 'train_lr': 0.020000800000000003, 'batch_time': 1.6761045440090852, 'data_time': 0.013517984916205423}
2025-10-31 07:31:33,816 - INFO - Step 2902: {'train_loss_batch': 6.190335273742676, 'train_lr': 0.020000800000000003, 'batch_time': 1.673462563322072, 'data_time': 0.010347797983602395}
2025-10-31 07:34:20,453 - INFO - Step 3002: {'train_loss_batch': 6.251305103302002, 'train_lr': 0.020000800000000003, 'batch_time': 1.6720462392666144, 'data_time': 0.008450436258982279}
2025-10-31 07:37:06,898 - INFO - Step 3102: {'train_loss_batch': 5.184309959411621, 'train_lr': 0.020000800000000003, 'batch_time': 1.6707813545392078, 'data_time': 0.007178967486998801}
2025-10-31 07:39:52,896 - INFO - Step 3202: {'train_loss_batch': 5.259538173675537, 'train_lr': 0.020000800000000003, 'batch_time': 1.6692414236136748, 'data_time': 0.006264755627228088}
2025-10-31 07:42:39,215 - INFO - Step 3302: {'train_loss_batch': 6.159075736999512, 'train_lr': 0.020000800000000003, 'batch_time': 1.6684846636954318, 'data_time': 0.005585670768842566}
2025-10-31 07:45:24,475 - INFO - Step 3402: {'train_loss_batch': 5.194337844848633, 'train_lr': 0.020000800000000003, 'batch_time': 1.6667221037052844, 'data_time': 0.005055388388173297}
2025-10-31 07:48:10,084 - INFO - Step 3502: {'train_loss_batch': 5.990414142608643, 'train_lr': 0.020000800000000003, 'batch_time': 1.665660050484565, 'data_time': 0.00463080739641523}
2025-10-31 07:50:55,538 - INFO - Step 3602: {'train_loss_batch': 5.295215129852295, 'train_lr': 0.020000800000000003, 'batch_time': 1.6646498265210117, 'data_time': 0.004281549860844279}
2025-10-31 07:53:41,782 - INFO - Step 3702: {'train_loss_batch': 5.8908305168151855, 'train_lr': 0.020000800000000003, 'batch_time': 1.6644651050075305, 'data_time': 0.003992814803302139}
2025-10-31 07:56:28,314 - INFO - Step 3802: {'train_loss_batch': 5.478476047515869, 'train_lr': 0.020000800000000003, 'batch_time': 1.664531326953674, 'data_time': 0.003748135782955794}
2025-10-31 07:59:14,264 - INFO - Step 3902: {'train_loss_batch': 5.016938209533691, 'train_lr': 0.020000800000000003, 'batch_time': 1.6641715987080936, 'data_time': 0.003537706100115344}
2025-10-31 08:02:00,949 - INFO - Step 4002: {'train_loss_batch': 5.49599552154541, 'train_lr': 0.020000800000000003, 'batch_time': 1.6643501389114004, 'data_time': 0.0033553729924577463}
2025-10-31 08:04:47,761 - INFO - Step 4102: {'train_loss_batch': 4.991265296936035, 'train_lr': 0.020000800000000003, 'batch_time': 1.6645851394372162, 'data_time': 0.003194933455858582}
2025-10-31 08:07:34,483 - INFO - Step 4202: {'train_loss_batch': 4.952882289886475, 'train_lr': 0.020000800000000003, 'batch_time': 1.6647404285825609, 'data_time': 0.0030541058360373952}
2025-10-31 08:10:21,062 - INFO - Step 4302: {'train_loss_batch': 5.1643218994140625, 'train_lr': 0.020000800000000003, 'batch_time': 1.664798222933128, 'data_time': 0.0029306589134000262}
2025-10-31 08:13:06,977 - INFO - Step 4402: {'train_loss_batch': 5.360556602478027, 'train_lr': 0.020000800000000003, 'batch_time': 1.664501175887957, 'data_time': 0.0028189134121191996}
2025-10-31 08:15:53,258 - INFO - Step 4502: {'train_loss_batch': 4.9454450607299805, 'train_lr': 0.020000800000000003, 'batch_time': 1.6644163448652107, 'data_time': 0.0027164167788313485}
2025-10-31 08:18:39,352 - INFO - Step 4602: {'train_loss_batch': 4.938023090362549, 'train_lr': 0.020000800000000003, 'batch_time': 1.664251196219886, 'data_time': 0.002624757286482116}
2025-10-31 08:21:26,014 - INFO - Step 4702: {'train_loss_batch': 5.664780616760254, 'train_lr': 0.020000800000000003, 'batch_time': 1.6643587445627825, 'data_time': 0.0025432073002996797}
2025-10-31 08:24:11,302 - INFO - Step 4802: {'train_loss_batch': 5.445873737335205, 'train_lr': 0.020000800000000003, 'batch_time': 1.6638598374727755, 'data_time': 0.002468454273096223}
2025-10-31 08:26:57,075 - INFO - Step 4902: {'train_loss_batch': 5.002461910247803, 'train_lr': 0.020000800000000003, 'batch_time': 1.6636040625796622, 'data_time': 0.0023989204762628405}
2025-10-31 08:29:43,754 - INFO - Step 5002: {'train_loss_batch': 5.939753532409668, 'train_lr': 0.020000800000000003, 'batch_time': 1.6637317392645907, 'data_time': 0.002363156433441028}
2025-10-31 08:31:28,210 - INFO - Step 1: {'epoch': 1, 'learning_rate': 0.040000600000000004, 'train_loss': 5.465357054528192, 'train_top1': 13.656049283596838, 'train_top5': 31.460752223320156, 'train_precision': 11.563118198758017, 'train_recall': 13.60073022185404, 'train_f1': 11.299881905138474, 'val_loss': 9.617153417053222, 'val_top1': 0.08, 'val_top5': 0.2499999999809265, 'val_precision': 0.10515247108307045, 'val_recall': 8.622502628811777e-05, 'val_f1': 0.00017230875939353287}
2025-10-31 08:31:28,211 - INFO - Epoch 001 Summary - LR: 0.040001, Train Loss: 5.4654, Train Top1: 13.66%, Val Loss: 9.6172, Val Top1: 0.08%, Val Top5: 0.25%, Val F1: 0.00%, Val Precision: 0.11%, Val Recall: 0.00%
2025-10-31 08:31:33,558 - INFO - Step 5004: {'train_loss_batch': 5.140745162963867, 'train_lr': 0.040000600000000004, 'batch_time': 5.345369338989258, 'data_time': 3.6825921535491943}
2025-10-31 08:34:19,710 - INFO - Step 5104: {'train_loss_batch': 4.904915809631348, 'train_lr': 0.040000600000000004, 'batch_time': 1.6979990690061362, 'data_time': 0.03727437954137821}
2025-10-31 08:37:03,963 - INFO - Step 5204: {'train_loss_batch': 4.938642501831055, 'train_lr': 0.040000600000000004, 'batch_time': 1.6704021911715987, 'data_time': 0.01913825315029467}
2025-10-31 08:39:50,401 - INFO - Step 5304: {'train_loss_batch': 5.818718910217285, 'train_lr': 0.040000600000000004, 'batch_time': 1.6684003240642358, 'data_time': 0.013044764433192257}
2025-10-31 08:42:37,252 - INFO - Step 5404: {'train_loss_batch': 4.915514945983887, 'train_lr': 0.040000600000000004, 'batch_time': 1.6684260992635218, 'data_time': 0.010002326489683994}
2025-10-31 08:45:23,386 - INFO - Step 5504: {'train_loss_batch': 4.872069835662842, 'train_lr': 0.040000600000000004, 'batch_time': 1.6670112600345572, 'data_time': 0.008169463056766106}
2025-10-31 08:48:08,823 - INFO - Step 5604: {'train_loss_batch': 5.948155403137207, 'train_lr': 0.040000600000000004, 'batch_time': 1.6649076633167743, 'data_time': 0.0069458325968407555}
2025-10-31 08:50:55,131 - INFO - Step 5704: {'train_loss_batch': 5.970192909240723, 'train_lr': 0.040000600000000004, 'batch_time': 1.6646471530326592, 'data_time': 0.006073942198052726}
2025-10-31 08:53:41,658 - INFO - Step 5804: {'train_loss_batch': 4.841090202331543, 'train_lr': 0.040000600000000004, 'batch_time': 1.6647250229648585, 'data_time': 0.005416848388652825}
2025-10-31 08:56:27,143 - INFO - Step 5904: {'train_loss_batch': 5.943941116333008, 'train_lr': 0.040000600000000004, 'batch_time': 1.663628785644599, 'data_time': 0.004904195550543883}
2025-10-31 08:59:12,505 - INFO - Step 6004: {'train_loss_batch': 5.745306968688965, 'train_lr': 0.040000600000000004, 'batch_time': 1.6626283696124127, 'data_time': 0.004494173305256146}
2025-10-31 09:01:58,585 - INFO - Step 6104: {'train_loss_batch': 5.73184871673584, 'train_lr': 0.040000600000000004, 'batch_time': 1.6624622251855363, 'data_time': 0.0041603130389082765}
2025-10-31 09:04:44,499 - INFO - Step 6204: {'train_loss_batch': 5.7327704429626465, 'train_lr': 0.040000600000000004, 'batch_time': 1.662185195879972, 'data_time': 0.003880253838659028}
2025-10-31 09:07:30,805 - INFO - Step 6304: {'train_loss_batch': 5.805776596069336, 'train_lr': 0.040000600000000004, 'batch_time': 1.66225226616328, 'data_time': 0.0036438370923827373}
2025-10-31 09:10:17,277 - INFO - Step 6404: {'train_loss_batch': 5.924933433532715, 'train_lr': 0.040000600000000004, 'batch_time': 1.6624284013520811, 'data_time': 0.0034407686115077015}
2025-10-31 09:13:02,706 - INFO - Step 6504: {'train_loss_batch': 4.669988632202148, 'train_lr': 0.040000600000000004, 'batch_time': 1.6618862047265324, 'data_time': 0.003265233773695954}
2025-10-31 09:15:48,986 - INFO - Step 6604: {'train_loss_batch': 5.464593887329102, 'train_lr': 0.040000600000000004, 'batch_time': 1.6619434761747875, 'data_time': 0.0031128520894095272}
2025-10-31 09:18:35,317 - INFO - Step 6704: {'train_loss_batch': 4.634791374206543, 'train_lr': 0.040000600000000004, 'batch_time': 1.6620233169658825, 'data_time': 0.002979147791652242}
2025-10-31 09:21:21,153 - INFO - Step 6804: {'train_loss_batch': 5.598756790161133, 'train_lr': 0.040000600000000004, 'batch_time': 1.6618199144582626, 'data_time': 0.002857782389308796}
2025-10-31 09:24:07,131 - INFO - Step 6904: {'train_loss_batch': 5.849826812744141, 'train_lr': 0.040000600000000004, 'batch_time': 1.6617122982001067, 'data_time': 0.002749716087995486}
2025-10-31 09:26:54,015 - INFO - Step 7004: {'train_loss_batch': 5.052037715911865, 'train_lr': 0.040000600000000004, 'batch_time': 1.6620685943420501, 'data_time': 0.002652640583394826}
2025-10-31 09:29:40,743 - INFO - Step 7104: {'train_loss_batch': 5.800760269165039, 'train_lr': 0.040000600000000004, 'batch_time': 1.6623165530286932, 'data_time': 0.0025645126222940016}
2025-10-31 09:32:27,448 - INFO - Step 7204: {'train_loss_batch': 4.603665828704834, 'train_lr': 0.040000600000000004, 'batch_time': 1.6625314080568943, 'data_time': 0.002484875990552612}
2025-10-31 09:35:13,698 - INFO - Step 7304: {'train_loss_batch': 4.4587860107421875, 'train_lr': 0.040000600000000004, 'batch_time': 1.6625301823415015, 'data_time': 0.002412123247003203}
2025-10-31 09:37:59,314 - INFO - Step 7404: {'train_loss_batch': 4.461480140686035, 'train_lr': 0.040000600000000004, 'batch_time': 1.6622648078270228, 'data_time': 0.0023449779996669376}
2025-10-31 09:40:45,945 - INFO - Step 7504: {'train_loss_batch': 5.1106157302856445, 'train_lr': 0.040000600000000004, 'batch_time': 1.6624263730443796, 'data_time': 0.0023055209106847985}
2025-10-31 09:42:30,945 - INFO - Step 2: {'epoch': 2, 'learning_rate': 0.0600004, 'train_loss': 5.171307453815695, 'train_top1': 18.92161349372385, 'train_top5': 40.01086885460251, 'train_precision': 16.985334944874605, 'train_recall': 18.81996375847123, 'train_f1': 16.89558480021128, 'val_loss': 8.984180868530274, 'val_top1': 0.2159999999809265, 'val_top5': 0.7239999999427795, 'val_precision': 0.10427528675703858, 'val_recall': 0.00022523461939520336, 'val_f1': 0.0004494983224139924}
2025-10-31 09:42:30,946 - INFO - Epoch 002 Summary - LR: 0.060000, Train Loss: 5.1713, Train Top1: 18.92%, Val Loss: 8.9842, Val Top1: 0.22%, Val Top5: 0.72%, Val F1: 0.00%, Val Precision: 0.10%, Val Recall: 0.00%
2025-10-31 09:42:32,011 - INFO - New best model saved with validation accuracy: 0.216%
2025-10-31 09:42:32,012 - INFO - Checkpoint saved: /home/ubuntu/imagenet-1k/checkpoints/resnet50_20251031_060921/checkpoint_epoch_003.pth
2025-10-31 09:42:37,548 - INFO - Step 7506: {'train_loss_batch': 4.45240592956543, 'train_lr': 0.0600004, 'batch_time': 5.535170078277588, 'data_time': 3.8869192600250244}
2025-10-31 09:45:23,379 - INFO - Step 7606: {'train_loss_batch': 4.583327770233154, 'train_lr': 0.0600004, 'batch_time': 1.6966977827619798, 'data_time': 0.03930867780553232}
2025-10-31 09:48:09,888 - INFO - Step 7706: {'train_loss_batch': 5.104249477386475, 'train_lr': 0.0600004, 'batch_time': 1.6809709463546525, 'data_time': 0.020168609287015242}
2025-10-31 09:50:56,088 - INFO - Step 7806: {'train_loss_batch': 4.978415012359619, 'train_lr': 0.0600004, 'batch_time': 1.6746668673036897, 'data_time': 0.013735128003497457}
2025-10-31 09:53:42,313 - INFO - Step 7906: {'train_loss_batch': 5.326656818389893, 'train_lr': 0.0600004, 'batch_time': 1.6715695263441661, 'data_time': 0.010510570093283333}
2025-10-31 09:56:28,550 - INFO - Step 8006: {'train_loss_batch': 5.85651969909668, 'train_lr': 0.0600004, 'batch_time': 1.669732852848228, 'data_time': 0.008573748632343467}
2025-10-31 09:59:13,975 - INFO - Step 8106: {'train_loss_batch': 5.124101638793945, 'train_lr': 0.0600004, 'batch_time': 1.6671564269581571, 'data_time': 0.007278797432110829}
2025-10-31 10:02:00,620 - INFO - Step 8206: {'train_loss_batch': 4.301032066345215, 'train_lr': 0.0600004, 'batch_time': 1.6670549667510768, 'data_time': 0.006360697508198388}
2025-10-31 10:04:47,128 - INFO - Step 8306: {'train_loss_batch': 4.582985877990723, 'train_lr': 0.0600004, 'batch_time': 1.6668080810303991, 'data_time': 0.005666679210877151}
2025-10-31 10:07:33,333 - INFO - Step 8406: {'train_loss_batch': 5.69964075088501, 'train_lr': 0.0600004, 'batch_time': 1.6662806220906687, 'data_time': 0.005127122478929661}
2025-10-31 10:10:19,363 - INFO - Step 8506: {'train_loss_batch': 4.549609184265137, 'train_lr': 0.0600004, 'batch_time': 1.6656830765746096, 'data_time': 0.004698035719392302}
2025-10-31 10:13:05,558 - INFO - Step 8606: {'train_loss_batch': 5.525636672973633, 'train_lr': 0.0600004, 'batch_time': 1.6653432365334326, 'data_time': 0.004344968120148786}
2025-10-31 10:15:49,952 - INFO - Step 8706: {'train_loss_batch': 4.337094306945801, 'train_lr': 0.0600004, 'batch_time': 1.663561293723482, 'data_time': 0.004052769234535796}
2025-10-31 10:18:36,780 - INFO - Step 8806: {'train_loss_batch': 4.439692974090576, 'train_lr': 0.0600004, 'batch_time': 1.6639241142331591, 'data_time': 0.0038043846083457063}
2025-10-31 10:21:22,616 - INFO - Step 8906: {'train_loss_batch': 4.354373931884766, 'train_lr': 0.0600004, 'batch_time': 1.6635261827669001, 'data_time': 0.0035888544582282533}
2025-10-31 10:24:07,907 - INFO - Step 9006: {'train_loss_batch': 4.84218168258667, 'train_lr': 0.0600004, 'batch_time': 1.6628189631734667, 'data_time': 0.003403913331460667}
2025-10-31 10:26:53,691 - INFO - Step 9106: {'train_loss_batch': 5.706840515136719, 'train_lr': 0.0600004, 'batch_time': 1.662508007290213, 'data_time': 0.0032429090520130852}
2025-10-31 10:29:39,568 - INFO - Step 9206: {'train_loss_batch': 5.379971027374268, 'train_lr': 0.0600004, 'batch_time': 1.6622883729693612, 'data_time': 0.0030997089608005746}
2025-10-31 10:32:25,383 - INFO - Step 9306: {'train_loss_batch': 4.203718185424805, 'train_lr': 0.0600004, 'batch_time': 1.662058176033236, 'data_time': 0.002971061264919215}
2025-10-31 10:35:11,432 - INFO - Step 9406: {'train_loss_batch': 4.073466777801514, 'train_lr': 0.0600004, 'batch_time': 1.6619756577956808, 'data_time': 0.0028586765140812377}
2025-10-31 10:37:57,826 - INFO - Step 9506: {'train_loss_batch': 4.293181419372559, 'train_lr': 0.0600004, 'batch_time': 1.6620738729127105, 'data_time': 0.00275721769223268}
2025-10-31 10:40:44,163 - INFO - Step 9606: {'train_loss_batch': 4.125662803649902, 'train_lr': 0.0600004, 'batch_time': 1.6621352934031643, 'data_time': 0.002664470150605773}
2025-10-31 10:43:30,823 - INFO - Step 9706: {'train_loss_batch': 4.076137065887451, 'train_lr': 0.0600004, 'batch_time': 1.662338107350413, 'data_time': 0.002580411105955367}
2025-10-31 10:46:17,306 - INFO - Step 9806: {'train_loss_batch': 4.837428092956543, 'train_lr': 0.0600004, 'batch_time': 1.662446481567111, 'data_time': 0.0025024953897700834}
2025-10-31 10:49:02,040 - INFO - Step 9906: {'train_loss_batch': 5.980520248413086, 'train_lr': 0.0600004, 'batch_time': 1.6618171896054714, 'data_time': 0.002431395152170228}
2025-10-31 10:51:48,044 - INFO - Step 10006: {'train_loss_batch': 5.885990142822266, 'train_lr': 0.0600004, 'batch_time': 1.6617458341408615, 'data_time': 0.002385291134248205}
2025-10-31 10:53:33,593 - INFO - Step 3: {'epoch': 3, 'learning_rate': 0.08000020000000001, 'train_loss': 4.840529351783314, 'train_top1': 25.189511138613863, 'train_top5': 48.632425742574256, 'train_precision': 23.493497826312893, 'train_recall': 25.088309229678618, 'train_f1': 23.541979826304214, 'val_loss': 9.034154647521973, 'val_top1': 0.18, 'val_top5': 0.4499999999809265, 'val_precision': 0.10193679918450561, 'val_recall': 0.0001834862385321101, 'val_f1': 0.00036631311345999216}
2025-10-31 10:53:33,595 - INFO - Epoch 003 Summary - LR: 0.080000, Train Loss: 4.8405, Train Top1: 25.19%, Val Loss: 9.0342, Val Top1: 0.18%, Val Top5: 0.45%, Val F1: 0.00%, Val Precision: 0.10%, Val Recall: 0.00%
2025-10-31 10:53:38,810 - INFO - Step 10008: {'train_loss_batch': 4.127928733825684, 'train_lr': 0.08000020000000001, 'batch_time': 5.213886022567749, 'data_time': 3.554856777191162}
2025-10-31 10:56:24,987 - INFO - Step 10108: {'train_loss_batch': 4.324027061462402, 'train_lr': 0.08000020000000001, 'batch_time': 1.696943757557633, 'data_time': 0.03601815676925206}
2025-10-31 10:59:11,395 - INFO - Step 10208: {'train_loss_batch': 4.194872856140137, 'train_lr': 0.08000020000000001, 'batch_time': 1.6805926614732885, 'data_time': 0.018495435145363878}
2025-10-31 11:01:56,894 - INFO - Step 10308: {'train_loss_batch': 3.9414448738098145, 'train_lr': 0.08000020000000001, 'batch_time': 1.6720848020129029, 'data_time': 0.012627798853522519}
2025-10-31 11:04:43,173 - INFO - Step 10408: {'train_loss_batch': 4.041898250579834, 'train_lr': 0.08000020000000001, 'batch_time': 1.6697656721842853, 'data_time': 0.009681802735364347}
2025-10-31 11:07:28,946 - INFO - Step 10508: {'train_loss_batch': 5.136007308959961, 'train_lr': 0.08000020000000001, 'batch_time': 1.667364207094539, 'data_time': 0.007911767788275986}
2025-10-31 11:10:14,763 - INFO - Step 10608: {'train_loss_batch': 4.056370258331299, 'train_lr': 0.08000020000000001, 'batch_time': 1.6658328539519858, 'data_time': 0.006730655267115639}
2025-10-31 11:13:00,972 - INFO - Step 10708: {'train_loss_batch': 4.165835380554199, 'train_lr': 0.08000020000000001, 'batch_time': 1.6652994115070339, 'data_time': 0.005886725454289631}
2025-10-31 11:15:46,830 - INFO - Step 10808: {'train_loss_batch': 4.098842144012451, 'train_lr': 0.08000020000000001, 'batch_time': 1.6644608867302368, 'data_time': 0.005251514480057429}
2025-10-31 11:18:31,538 - INFO - Step 10908: {'train_loss_batch': 5.566903114318848, 'train_lr': 0.08000020000000001, 'batch_time': 1.6625307267831513, 'data_time': 0.004758278087823425}
2025-10-31 11:21:17,932 - INFO - Step 11008: {'train_loss_batch': 4.668825149536133, 'train_lr': 0.08000020000000001, 'batch_time': 1.6626719651998698, 'data_time': 0.0043635925689300935}
2025-10-31 11:24:04,511 - INFO - Step 11108: {'train_loss_batch': 3.8826241493225098, 'train_lr': 0.08000020000000001, 'batch_time': 1.6629547650547702, 'data_time': 0.004040078614431549}
2025-10-31 11:26:50,784 - INFO - Step 11208: {'train_loss_batch': 3.913337469100952, 'train_lr': 0.08000020000000001, 'batch_time': 1.6629359132542796, 'data_time': 0.0037699375025537192}
2025-10-31 11:29:35,998 - INFO - Step 11308: {'train_loss_batch': 4.282164573669434, 'train_lr': 0.08000020000000001, 'batch_time': 1.6621052557280391, 'data_time': 0.003542031076300795}
2025-10-31 11:32:21,212 - INFO - Step 11408: {'train_loss_batch': 4.054646015167236, 'train_lr': 0.08000020000000001, 'batch_time': 1.6613944284750852, 'data_time': 0.0033483324860947884}
2025-10-31 11:35:07,330 - INFO - Step 11508: {'train_loss_batch': 5.515364646911621, 'train_lr': 0.08000020000000001, 'batch_time': 1.661380163436727, 'data_time': 0.0031784201843749675}
2025-10-31 11:37:53,788 - INFO - Step 11608: {'train_loss_batch': 3.835081100463867, 'train_lr': 0.08000020000000001, 'batch_time': 1.6615796226177417, 'data_time': 0.0030310837497270382}
2025-10-31 11:40:40,421 - INFO - Step 11708: {'train_loss_batch': 3.9312994480133057, 'train_lr': 0.08000020000000001, 'batch_time': 1.6618590444624248, 'data_time': 0.0028998212629314873}
2025-10-31 11:43:26,419 - INFO - Step 11808: {'train_loss_batch': 4.418830871582031, 'train_lr': 0.08000020000000001, 'batch_time': 1.6617540545360305, 'data_time': 0.0027848007545280564}
2025-10-31 11:46:12,891 - INFO - Step 11908: {'train_loss_batch': 4.882932662963867, 'train_lr': 0.08000020000000001, 'batch_time': 1.661910402467538, 'data_time': 0.0026810673398133767}
2025-10-31 11:48:59,170 - INFO - Step 12008: {'train_loss_batch': 3.8274359703063965, 'train_lr': 0.08000020000000001, 'batch_time': 1.6619544447451338, 'data_time': 0.0025875006003239225}
2025-10-31 11:51:45,287 - INFO - Step 12108: {'train_loss_batch': 5.389920234680176, 'train_lr': 0.08000020000000001, 'batch_time': 1.661916986753236, 'data_time': 0.0025024465127878675}
2025-10-31 11:54:31,307 - INFO - Step 12208: {'train_loss_batch': 4.151965618133545, 'train_lr': 0.08000020000000001, 'batch_time': 1.6618387577805611, 'data_time': 0.002425599347348107}
2025-10-31 11:57:17,711 - INFO - Step 12308: {'train_loss_batch': 3.945028305053711, 'train_lr': 0.08000020000000001, 'batch_time': 1.6619341588963223, 'data_time': 0.00235568021287715}
2025-10-31 12:00:04,268 - INFO - Step 12408: {'train_loss_batch': 4.929868698120117, 'train_lr': 0.08000020000000001, 'batch_time': 1.6620857736459627, 'data_time': 0.002290620351026377}
2025-10-31 12:02:50,704 - INFO - Step 12508: {'train_loss_batch': 5.305978775024414, 'train_lr': 0.08000020000000001, 'batch_time': 1.662176635540852, 'data_time': 0.002248458126362492}
2025-10-31 12:04:36,134 - INFO - Step 4: {'epoch': 4, 'learning_rate': 0.1, 'train_loss': 4.5715269835637535, 'train_top1': 31.182556761477045, 'train_top5': 55.80557634730539, 'train_precision': 29.794749387868475, 'train_recall': 31.017613145702843, 'train_f1': 29.81753224525831, 'val_loss': 9.993104310302733, 'val_top1': 0.068, 'val_top5': 0.17599999998092652, 'val_precision': 0.10152284263959391, 'val_recall': 6.903553299492386e-05, 'val_f1': 0.00013797724146565106}
2025-10-31 12:04:36,135 - INFO - Epoch 004 Summary - LR: 0.100000, Train Loss: 4.5715, Train Top1: 31.18%, Val Loss: 9.9931, Val Top1: 0.07%, Val Top5: 0.18%, Val F1: 0.00%, Val Precision: 0.10%, Val Recall: 0.00%
2025-10-31 12:04:41,679 - INFO - Step 12510: {'train_loss_batch': 5.578196048736572, 'train_lr': 0.1, 'batch_time': 5.542326211929321, 'data_time': 3.8594250679016113}
2025-10-31 12:07:28,435 - INFO - Step 12610: {'train_loss_batch': 5.059905052185059, 'train_lr': 0.1, 'batch_time': 1.7059276505271987, 'data_time': 0.039046096329641816}
2025-10-31 12:10:14,345 - INFO - Step 12710: {'train_loss_batch': 3.7929024696350098, 'train_lr': 0.1, 'batch_time': 1.682625551128862, 'data_time': 0.020028431024124372}
2025-10-31 12:13:00,352 - INFO - Step 12810: {'train_loss_batch': 3.983459949493408, 'train_lr': 0.1, 'batch_time': 1.6751333336497463, 'data_time': 0.013649729795234149}
2025-10-31 12:15:46,583 - INFO - Step 12910: {'train_loss_batch': 5.527707099914551, 'train_lr': 0.1, 'batch_time': 1.6719349007356792, 'data_time': 0.010456592959358805}
2025-10-31 12:18:32,829 - INFO - Step 13010: {'train_loss_batch': 3.9710302352905273, 'train_lr': 0.1, 'batch_time': 1.6700438553701618, 'data_time': 0.008545694712869183}
2025-10-31 12:21:19,075 - INFO - Step 13110: {'train_loss_batch': 3.8898189067840576, 'train_lr': 0.1, 'batch_time': 1.668780863582592, 'data_time': 0.007255336409202233}
2025-10-31 12:24:05,592 - INFO - Step 13210: {'train_loss_batch': 5.40915584564209, 'train_lr': 0.1, 'batch_time': 1.6682659484520448, 'data_time': 0.006334897284841061}
2025-10-31 12:26:52,303 - INFO - Step 13310: {'train_loss_batch': 5.294469833374023, 'train_lr': 0.1, 'batch_time': 1.6681205565563302, 'data_time': 0.005647334266691172}
2025-10-31 12:29:38,817 - INFO - Step 13410: {'train_loss_batch': 3.761167526245117, 'train_lr': 0.1, 'batch_time': 1.667790505782878, 'data_time': 0.005110443498397641}
2025-10-31 12:32:24,625 - INFO - Step 13510: {'train_loss_batch': 3.635244369506836, 'train_lr': 0.1, 'batch_time': 1.6668195588724477, 'data_time': 0.004681284253771131}
2025-10-31 12:35:09,979 - INFO - Step 13610: {'train_loss_batch': 3.7859244346618652, 'train_lr': 0.1, 'batch_time': 1.6656135614085046, 'data_time': 0.0043330736099645075}
2025-10-31 12:37:55,716 - INFO - Step 13710: {'train_loss_batch': 3.838212728500366, 'train_lr': 0.1, 'batch_time': 1.6649273152553867, 'data_time': 0.004038436922999246}
2025-10-31 12:40:40,523 - INFO - Step 13810: {'train_loss_batch': 3.8412675857543945, 'train_lr': 0.1, 'batch_time': 1.6636314694465444, 'data_time': 0.0037903763714613684}
2025-10-31 12:43:26,716 - INFO - Step 13910: {'train_loss_batch': 3.8077003955841064, 'train_lr': 0.1, 'batch_time': 1.663509442413134, 'data_time': 0.0035783534897471394}
2025-10-31 12:46:11,774 - INFO - Step 14010: {'train_loss_batch': 3.807399272918701, 'train_lr': 0.1, 'batch_time': 1.662648032300874, 'data_time': 0.0033926506347452933}
2025-10-31 12:48:57,890 - INFO - Step 14110: {'train_loss_batch': 3.7729434967041016, 'train_lr': 0.1, 'batch_time': 1.6625551922778499, 'data_time': 0.003231279556636584}
2025-10-31 12:51:43,967 - INFO - Step 14210: {'train_loss_batch': 3.7856078147888184, 'train_lr': 0.1, 'batch_time': 1.6624501171986683, 'data_time': 0.003088780952018545}
2025-10-31 12:54:28,595 - INFO - Step 14310: {'train_loss_batch': 3.700082778930664, 'train_lr': 0.1, 'batch_time': 1.6615522205664144, 'data_time': 0.0029623196033687475}
2025-10-31 12:57:13,928 - INFO - Step 14410: {'train_loss_batch': 3.614527702331543, 'train_lr': 0.1, 'batch_time': 1.6611195636510472, 'data_time': 0.00284958261994548}
2025-10-31 12:59:59,261 - INFO - Step 14510: {'train_loss_batch': 3.5879383087158203, 'train_lr': 0.1, 'batch_time': 1.6607299552805004, 'data_time': 0.0027482952849975767}
2025-10-31 13:02:45,661 - INFO - Step 14610: {'train_loss_batch': 4.8833723068237305, 'train_lr': 0.1, 'batch_time': 1.6608859006136387, 'data_time': 0.002657180738017878}
2025-10-31 13:05:31,633 - INFO - Step 14710: {'train_loss_batch': 5.212078094482422, 'train_lr': 0.1, 'batch_time': 1.6608326814219065, 'data_time': 0.002572636017199269}
2025-10-31 13:08:18,044 - INFO - Step 14810: {'train_loss_batch': 3.5345633029937744, 'train_lr': 0.1, 'batch_time': 1.6609751507801784, 'data_time': 0.0024985417445189846}
2025-10-31 13:11:03,850 - INFO - Step 14910: {'train_loss_batch': 3.5942370891571045, 'train_lr': 0.1, 'batch_time': 1.660853423559879, 'data_time': 0.002427864253446491}
2025-10-31 13:13:49,977 - INFO - Step 15010: {'train_loss_batch': 5.062833309173584, 'train_lr': 0.1, 'batch_time': 1.6608699724608447, 'data_time': 0.002381973960598866}
