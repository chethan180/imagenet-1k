{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision timm albumentations opencv-python tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1ik46yIKELl",
        "outputId": "e048312c-940f-4945-b7db-2d1127452d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.10)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_DIR = \"/content/drive/MyDrive/datasets/tiny-imagenet-200\"\n",
        "\n",
        "!mkdir -p $DATA_DIR\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip -O /content/drive/MyDrive/datasets/tiny-imagenet-200.zip\n",
        "!unzip -q /content/drive/MyDrive/datasets/tiny-imagenet-200.zip -d /content/drive/MyDrive/datasets/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBXAQUv7Kyhx",
        "outputId": "b9bd45b8-d8fb-494d-eeb8-c92abb02528b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2025-10-16 04:08:50--  https://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘/content/drive/MyDrive/datasets/tiny-imagenet-200.zip’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>] 236.61M  18.7MB/s    in 22s     \n",
            "\n",
            "2025-10-16 04:09:13 (10.7 MB/s) - ‘/content/drive/MyDrive/datasets/tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5_SIkJZJwMt",
        "outputId": "5d496c33-772b-40e4-8a3e-614c8d9fdfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from timm.models import create_model\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.utils import accuracy, AverageMeter, ModelEmaV2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ Enable cuDNN auto-tuning for faster convolutions\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "# ===================== DATASET WRAPPER =====================\n",
        "class AlbumentationsImageDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.dataset = datasets.ImageFolder(root)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.dataset.imgs[idx]\n",
        "        image = np.array(self.dataset.loader(path).convert('RGB'))\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# ===================== TRAINING FUNCTION =====================\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch, mixup_fn=None, ema=None):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # ✅ tqdm progress bar per batch\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch}\", ncols=100, leave=False)\n",
        "    for images, targets in progress_bar:\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        if mixup_fn is not None:\n",
        "            images, targets = mixup_fn(images, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if ema:\n",
        "            ema.update(model)\n",
        "\n",
        "        # Accuracy calc\n",
        "        acc_targets = torch.argmax(targets, dim=1) if targets.ndim > 1 else targets\n",
        "        acc1, _ = accuracy(output, acc_targets, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1.item(), images.size(0))\n",
        "        progress_bar.set_postfix(loss=f\"{losses.avg:.3f}\", acc=f\"{top1.avg:.2f}\")\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"\\nTrain Epoch {epoch}: Loss {losses.avg:.4f}, Acc@1 {top1.avg:.2f}, Time {epoch_time/60:.2f} min\")\n",
        "    return losses.avg, top1.avg, epoch_time\n",
        "\n",
        "\n",
        "# ===================== VALIDATION FUNCTION =====================\n",
        "@torch.no_grad()\n",
        "def validate(model, dataloader, criterion, device, ema=None):\n",
        "    model.eval()\n",
        "    if ema:\n",
        "        model = ema.module\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    for images, targets in tqdm(dataloader, desc=\"Validating\", ncols=100, leave=False):\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        output = model(images)\n",
        "        loss = criterion(output, targets)\n",
        "        acc1, _ = accuracy(output, targets, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1.item(), images.size(0))\n",
        "\n",
        "    print(f\"Validation: Loss {losses.avg:.4f}, Acc@1 {top1.avg:.2f}\")\n",
        "    return losses.avg, top1.avg\n",
        "\n",
        "\n",
        "# ===================== MAIN =====================\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--data', type=str, default='./tiny-imagenet-200')\n",
        "    parser.add_argument('--epochs', type=int, default=10)\n",
        "    parser.add_argument('--batch_size', type=int, default=128)\n",
        "    parser.add_argument('--lr', type=float, default=0.05)\n",
        "    parser.add_argument('--num-classes', type=int, default=200)\n",
        "    parser.add_argument('--mixup', type=float, default=0.3)\n",
        "    parser.add_argument('--cutmix', type=float, default=0.3)\n",
        "    parser.add_argument('--ema-decay', type=float, default=0.9998)\n",
        "    parser.add_argument('--label-smoothing', type=float, default=0.1)\n",
        "    parser.add_argument('--workers', type=int, default=4)\n",
        "    parser.add_argument('--save', type=str, default='./checkpoints')\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    os.makedirs(args.save, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    COARSE_DROPOUT_FILL = tuple([int(x * 255) for x in MEAN])\n",
        "\n",
        "    train_tfms = A.Compose([\n",
        "        A.RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0)),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.CoarseDropout(max_holes=1, max_height=8, max_width=8, fill_value=COARSE_DROPOUT_FILL, p=0.3),\n",
        "        A.Normalize(mean=MEAN, std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    val_tfms = A.Compose([\n",
        "        A.Resize(height=256, width=256),\n",
        "        A.CenterCrop(height=224, width=224),\n",
        "        A.Normalize(mean=MEAN, std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    train_dataset = AlbumentationsImageDataset(os.path.join(args.data, 'train'), transform=train_tfms)\n",
        "    val_dataset = AlbumentationsImageDataset(os.path.join(args.data, 'val'), transform=val_tfms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "                              num_workers=args.workers, pin_memory=True, persistent_workers=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "                            num_workers=args.workers, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "    model = create_model('resnet50', pretrained=False, num_classes=args.num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=args.label_smoothing)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "    mixup_fn = Mixup(mixup_alpha=args.mixup, cutmix_alpha=args.cutmix,\n",
        "                     label_smoothing=args.label_smoothing, num_classes=args.num_classes)\n",
        "    ema = ModelEmaV2(model, decay=args.ema_decay, device=device)\n",
        "\n",
        "    best_acc = 0\n",
        "    train_losses, val_losses, train_accs, val_accs, epoch_times = [], [], [], [], []\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_loss, train_acc, epoch_time = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, mixup_fn, ema)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device, ema)\n",
        "        scheduler.step()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        epoch_times.append(epoch_time)\n",
        "\n",
        "        # ✅ Save best model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({\n",
        "                'model': model.state_dict(),\n",
        "                'ema': ema.module.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'val_acc': val_acc\n",
        "            }, os.path.join(args.save, 'best.pth'))\n",
        "\n",
        "        # ✅ Save checkpoint every 10 epochs\n",
        "        if epoch % 10 == 0 or epoch == args.epochs:\n",
        "            ckpt_path = os.path.join(args.save, f'checkpoint_epoch{epoch}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model': model.state_dict(),\n",
        "                'ema': ema.module.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "            }, ckpt_path)\n",
        "            print(f\"💾 Saved checkpoint: {ckpt_path}\")\n",
        "\n",
        "            # Plot progress\n",
        "            plt.figure(figsize=(8, 5))\n",
        "            plt.plot(range(1, len(train_accs)+1), train_accs, label='Train Acc', marker='o')\n",
        "            plt.plot(range(1, len(val_accs)+1), val_accs, label='Val Acc', marker='o')\n",
        "            plt.title('Accuracy vs Epochs')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Accuracy (%)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(args.save, f'plot_epoch{epoch}.png'))\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"✅ Epoch {epoch} done. Best Acc so far: {best_acc:.2f}%\")\n",
        "\n",
        "    total_time = sum(epoch_times)\n",
        "    print(f\"🏁 Training complete! Best Top-1: {best_acc:.2f}%, Total Time: {total_time/60:.2f} min\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Check"
      ],
      "metadata": {
        "id": "rz2VHGJRLtiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train.py --data ./tiny-imagenet-200 --epochs 2 --batch_size 32"
      ],
      "metadata": {
        "id": "qDZV5lEHLXe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imagenet-200 testing"
      ],
      "metadata": {
        "id": "a2CUu-h2LwYL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WQ34-VgDjjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data /content/drive/MyDrive/datasets/tiny-imagenet-200 \\\n",
        "  --epochs 50 \\\n",
        "  --batch_size 128 \\\n",
        "  --lr 1e-3 \\\n",
        "  --workers 2 \\\n",
        "  --save ./runs/tiny_albu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Y8ep3_J686",
        "outputId": "e691da70-cd50-42cd-e271-d53ab5c9ed7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/train.py:120: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=1, max_height=8, max_width=8, fill_value=COARSE_DROPOUT_FILL, p=0.3),\n",
            "Epoch 1:   0%|                                                              | 0/782 [00:00<?, ?it/s]/content/train.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "                                                                                                    \n",
            "Train Epoch 1: Loss 5.1943, Acc@1 2.71, Time 9.35 min\n",
            "Validation: Loss 5.3322, Acc@1 0.00\n",
            "✅ Epoch 1 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 2: Loss 5.1012, Acc@1 4.12, Time 8.88 min\n",
            "Validation: Loss 5.3587, Acc@1 0.00\n",
            "✅ Epoch 2 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 3: Loss 5.0633, Acc@1 4.67, Time 8.91 min\n",
            "Validation: Loss 5.3908, Acc@1 0.00\n",
            "✅ Epoch 3 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 4: Loss 5.0415, Acc@1 5.11, Time 8.85 min\n",
            "Validation: Loss 5.4273, Acc@1 0.00\n",
            "✅ Epoch 4 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 5: Loss 5.0287, Acc@1 5.51, Time 8.84 min\n",
            "Validation: Loss 5.4703, Acc@1 0.00\n",
            "✅ Epoch 5 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 6: Loss 5.0186, Acc@1 5.57, Time 8.79 min\n",
            "Validation: Loss 5.5182, Acc@1 0.00\n",
            "✅ Epoch 6 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 7: Loss 5.0035, Acc@1 6.06, Time 8.82 min\n",
            "Validation: Loss 5.5655, Acc@1 0.00\n",
            "✅ Epoch 7 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 8: Loss 4.9965, Acc@1 6.04, Time 8.97 min\n",
            "Validation: Loss 5.6223, Acc@1 0.00\n",
            "✅ Epoch 8 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 9: Loss 4.9744, Acc@1 6.41, Time 8.89 min\n",
            "Validation: Loss 5.6770, Acc@1 0.00\n",
            "✅ Epoch 9 done. Best Acc so far: 0.00%\n",
            "                                                                                                    \n",
            "Train Epoch 10: Loss 4.9749, Acc@1 6.49, Time 8.81 min\n",
            "Validation: Loss 5.7281, Acc@1 0.00\n",
            "💾 Saved checkpoint: ./runs/tiny_albu/checkpoint_epoch10.pth\n",
            "✅ Epoch 10 done. Best Acc so far: 0.00%\n",
            "Epoch 11:   0%|                                                             | 0/782 [00:00<?, ?it/s]/content/train.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "                                                                                                    \n",
            "Train Epoch 11: Loss 4.9681, Acc@1 6.76, Time 8.87 min\n",
            "Validation: Loss 5.7736, Acc@1 0.00\n",
            "✅ Epoch 11 done. Best Acc so far: 0.00%\n",
            "Epoch 12:  86%|████████████████████████▉    | 672/782 [07:33<01:14,  1.48it/s, acc=6.71, loss=4.965]"
          ]
        }
      ]
    }
  ]
}