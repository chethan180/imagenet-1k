{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtjFQER_4_VX",
        "outputId": "006b3a5f-25cf-42b5-8b52-1ba8b75ea542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading TinyImageNet...\n",
            "--2025-10-17 15:57:48--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs231n.stanford.edu/tiny-imagenet-200.zip [following]\n",
            "--2025-10-17 15:57:48--  https://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  6.94MB/s    in 32s     \n",
            "\n",
            "2025-10-17 15:58:21 (7.47 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n",
            "Preparing validation data directory structure...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "# --- Download and Prepare TinyImageNet ---\n",
        "print(\"Downloading TinyImageNet...\")\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip\n",
        "\n",
        "# --- Prepare Validation Data Directory Structure ---\n",
        "print(\"Preparing validation data directory structure...\")\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "\n",
        "val_images_dir = './tiny-imagenet-200/val/images'\n",
        "val_dest_dir = './tiny-imagenet-200/val/'\n",
        "\n",
        "for index, row in val_data.iterrows():\n",
        "    class_dir = os.path.join(val_dest_dir, row['Class'])\n",
        "    if not os.path.exists(class_dir):\n",
        "        os.makedirs(class_dir)\n",
        "    image_path = os.path.join(val_images_dir, row['File'])\n",
        "    dest_path = os.path.join(class_dir, row['File'])\n",
        "    os.rename(image_path, dest_path)\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = \"./tiny-imagenet-200\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMDNWFKp6L13"
      },
      "source": [
        "## Configuration and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFOFC7N86hQF",
        "outputId": "30109d2d-8b42-41f5-b61a-ff86f40218df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixing validation directory structure...\n",
            "Removing ./tiny-imagenet-200/val/images...\n",
            "Renaming .JPEG files to .jpeg...\n",
            "Completed renaming in train directory\n",
            "Completed renaming in val directory\n",
            "Fix complete! Now proceed with Checkpoint 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Fixing validation directory structure...\")\n",
        "\n",
        "# Remove the old images directory if it exists\n",
        "val_images_dir = './tiny-imagenet-200/val/images'\n",
        "if os.path.exists(val_images_dir):\n",
        "    print(f\"Removing {val_images_dir}...\")\n",
        "    shutil.rmtree(val_images_dir)\n",
        "\n",
        "# Rename all .JPEG files to .jpeg in both train and val directories\n",
        "print(\"Renaming .JPEG files to .jpeg...\")\n",
        "\n",
        "for split in ['train', 'val']:\n",
        "    split_dir = os.path.join('./tiny-imagenet-200', split)\n",
        "    if os.path.exists(split_dir):\n",
        "        # Walk through all subdirectories\n",
        "        for root, dirs, files in os.walk(split_dir):\n",
        "            for filename in files:\n",
        "                if filename.endswith('.JPEG'):\n",
        "                    old_path = os.path.join(root, filename)\n",
        "                    new_filename = filename.replace('.JPEG', '.jpeg')\n",
        "                    new_path = os.path.join(root, new_filename)\n",
        "                    os.rename(old_path, new_path)\n",
        "        print(f\"Completed renaming in {split} directory\")\n",
        "\n",
        "print(\"Fix complete! Now proceed with Checkpoint 1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81uV0wfQ6HVi",
        "outputId": "38e52142-2ad3-4406-db7c-32e6306a6f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Batch Size: 256, Workers: 2, Epochs: 50\n",
            "\n",
            "Loading datasets...\n",
            "Train dataset size: 100000, Validation dataset size: 10000\n",
            "Number of classes: 200\n"
          ]
        }
      ],
      "source": [
        "# --- Configuration ---\n",
        "DATA_DIR = \"./tiny-imagenet-200\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "NUM_CLASSES = 200  # TinyImageNet has 200 classes\n",
        "BATCH_SIZE = 256 if torch.cuda.is_available() else 32\n",
        "NUM_WORKERS = 2  # Adjusted for Colab\n",
        "EPOCHS = 50\n",
        "WEIGHT_DECAY = 0.0005\n",
        "MOMENTUM = 0.9\n",
        "LABEL_SMOOTHING = 0.1\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}, Workers: {NUM_WORKERS}, Epochs: {EPOCHS}\")\n",
        "\n",
        "# --- Data Augmentation and Loading ---\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"\\nLoading datasets...\")\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=(x=='train'),\n",
        "                             num_workers=NUM_WORKERS, pin_memory=True)\n",
        "               for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "classes = image_datasets['train'].classes\n",
        "print(f\"Train dataset size: {dataset_sizes['train']}, Validation dataset size: {dataset_sizes['val']}\")\n",
        "print(f\"Number of classes: {len(classes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-oUepI66092"
      },
      "source": [
        "## Model Setup and Loss/Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1Ny3uuP6n1X",
        "outputId": "222139a3-ab9a-478a-c670-7998b4e1f937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up ResNet-50 model...\n",
            "Model setup complete!\n",
            "Total parameters: 23,917,832\n"
          ]
        }
      ],
      "source": [
        "# --- Model Setup (ResNet-50) ---\n",
        "print(\"\\nSetting up ResNet-50 model...\")\n",
        "model = models.resnet50(weights=None, num_classes=NUM_CLASSES)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY, nesterov=True)\n",
        "\n",
        "print(\"Model setup complete!\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsrcaQ5D7E0p"
      },
      "source": [
        "## LR Finder Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E2ehFKi7FsP",
        "outputId": "0f092cff-e739-4e9d-823a-9c0876095866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR Finder class defined!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# LR Finder Implementation\n",
        "# ==============================================================================\n",
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        self.history = {'lr': [], 'loss': [], 'acc': []}\n",
        "\n",
        "    def range_test(self, dataloader, start_lr=1e-4, end_lr=1, num_iter=100):\n",
        "        \"\"\"Find optimal learning rate\"\"\"\n",
        "        self.model.train()\n",
        "        lr_mult = (end_lr / start_lr) ** (1 / num_iter)\n",
        "        lr = start_lr\n",
        "\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        iter_count = 0\n",
        "        running_loss = 0\n",
        "        running_acc = 0\n",
        "        pbar = tqdm(dataloader, desc='LR Range Test', total=num_iter)\n",
        "\n",
        "        for inputs, labels in pbar:\n",
        "            if iter_count >= num_iter:\n",
        "                break\n",
        "\n",
        "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            acc = (preds == labels).float().mean().item()\n",
        "\n",
        "            running_loss = 0.9 * running_loss + 0.1 * loss.item()\n",
        "            running_acc = 0.9 * running_acc + 0.1 * acc\n",
        "\n",
        "            self.history['lr'].append(lr)\n",
        "            self.history['loss'].append(running_loss)\n",
        "            self.history['acc'].append(running_acc)\n",
        "\n",
        "            # Update learning rate\n",
        "            lr *= lr_mult\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "            pbar.set_postfix(lr=f'{lr:.2e}', loss=f'{running_loss:.4f}', acc=f'{running_acc:.4f}')\n",
        "            iter_count += 1\n",
        "\n",
        "    def plot(self, plot_case=\"loss\"):\n",
        "        \"\"\"Plot LR finder results\"\"\"\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        if plot_case == \"loss\":\n",
        "            ax.plot(self.history['lr'], self.history['loss'])\n",
        "            ax.set_ylabel('Loss')\n",
        "            ax.set_title('LR Finder - Loss')\n",
        "        else:\n",
        "            ax.plot(self.history['lr'], self.history['acc'])\n",
        "            ax.set_ylabel('Accuracy')\n",
        "            ax.set_title('LR Finder - Accuracy')\n",
        "        ax.set_xlabel('Learning Rate')\n",
        "        ax.set_xscale('log')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def get_best_lr(self, case=\"loss\"):\n",
        "        \"\"\"Get the best learning rate\"\"\"\n",
        "        if case == \"loss\":\n",
        "            # Find LR with minimum loss (after initial descent)\n",
        "            min_idx = np.argmin(self.history['loss'][10:]) + 10\n",
        "            best_lr = self.history['lr'][min_idx]\n",
        "        else:\n",
        "            # Find LR with maximum accuracy\n",
        "            max_idx = np.argmax(self.history['acc'])\n",
        "            best_lr = self.history['lr'][max_idx]\n",
        "        print(f\"Best LR ({case}): {best_lr:.2e}\")\n",
        "        return best_lr\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset model and optimizer to initial state\"\"\"\n",
        "        self.model.load_state_dict(self.initial_state_dict)\n",
        "        self.optimizer.load_state_dict(self.initial_optimizer_state)\n",
        "\n",
        "print(\"LR Finder class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bll1OEXM7KFo"
      },
      "source": [
        "## Trainer and Tester Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS5Dip3z7GtW",
        "outputId": "adf628d8-9516-405f-e09a-f3e56e3035d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainer and Tester classes defined!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Training and Testing Functions\n",
        "# ==============================================================================\n",
        "class Trainer:\n",
        "    def __init__(self):\n",
        "        self.train_losses = []\n",
        "        self.train_acc = []\n",
        "\n",
        "    def train(self, model, device, train_loader, optimizer, criterion, scheduler=None):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc='Training')\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Update progress bar\n",
        "            curr_acc = 100. * correct / total\n",
        "            curr_loss = running_loss / total\n",
        "            lr = optimizer.param_groups[0]['lr'] if scheduler else optimizer.param_groups[0]['lr']\n",
        "            pbar.set_postfix(loss=f'{curr_loss:.4f}', acc=f'{curr_acc:.2f}%', lr=f'{lr:.2e}')\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "        self.train_losses.append(epoch_loss)\n",
        "        self.train_acc.append(epoch_acc)\n",
        "\n",
        "        return epoch_loss, epoch_acc\n",
        "\n",
        "class Tester:\n",
        "    def __init__(self):\n",
        "        self.test_losses = []\n",
        "        self.test_acc = []\n",
        "        self.misclassified_images = []\n",
        "        self.trueclassified_images = []\n",
        "\n",
        "    def test(self, model, device, test_loader, criterion, misclassfied_required=False,\n",
        "             trueclassified_required=False, classes=None, class_accuracy=90):\n",
        "        \"\"\"Test the model\"\"\"\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        self.misclassified_images = []\n",
        "        self.trueclassified_images = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(test_loader, desc='Testing')\n",
        "            for inputs, labels in pbar:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "                # Store misclassified images\n",
        "                if misclassfied_required:\n",
        "                    mask = preds != labels\n",
        "                    for i in range(len(mask)):\n",
        "                        if mask[i] and len(self.misclassified_images) < 20:\n",
        "                            self.misclassified_images.append({\n",
        "                                'image': inputs[i].cpu(),\n",
        "                                'pred': preds[i].item(),\n",
        "                                'true': labels[i].item()\n",
        "                            })\n",
        "\n",
        "                # Store correctly classified images\n",
        "                if trueclassified_required:\n",
        "                    mask = preds == labels\n",
        "                    for i in range(len(mask)):\n",
        "                        if mask[i] and len(self.trueclassified_images) < 20:\n",
        "                            self.trueclassified_images.append({\n",
        "                                'image': inputs[i].cpu(),\n",
        "                                'pred': preds[i].item(),\n",
        "                                'true': labels[i].item()\n",
        "                            })\n",
        "\n",
        "                # Update progress bar\n",
        "                curr_acc = 100. * correct / total\n",
        "                pbar.set_postfix(acc=f'{curr_acc:.2f}%')\n",
        "\n",
        "        epoch_loss = running_loss / len(test_loader.dataset)\n",
        "        epoch_acc = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "        self.test_losses.append(epoch_loss)\n",
        "        self.test_acc.append(epoch_acc)\n",
        "\n",
        "        print(f'Test Loss: {epoch_loss:.4f}, Test Acc: {epoch_acc:.2f}%')\n",
        "\n",
        "        return epoch_loss, epoch_acc\n",
        "\n",
        "print(\"Trainer and Tester classes defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8slt4Z-7RMm"
      },
      "source": [
        "## Utility Functions (Save/Load and Plotter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsZJFzvF7M3h",
        "outputId": "3fa78197-5856-488b-8af3-a6e1c7b17f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utility functions defined!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Model Save/Load and Plotting Utilities\n",
        "# ==============================================================================\n",
        "\n",
        "def save_model(model, optimizer, criterion, scheduler, epoch, train_acc, train_loss, lr, test_acc, test_loss, file_name):\n",
        "    \"\"\"Save model checkpoint\"\"\"\n",
        "    checkpoint = {\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict(),\n",
        "        'criterion': criterion,\n",
        "        'epochs': epoch,\n",
        "        'train_acc': train_acc,\n",
        "        'train_loss': train_loss,\n",
        "        'lr': lr,\n",
        "        'test_acc': test_acc,\n",
        "        'test_loss': test_loss\n",
        "    }\n",
        "    torch.save(checkpoint, file_name)\n",
        "    print(f\"Model saved to {file_name}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, scheduler, criterion, filename='checkpoint.pth'):\n",
        "    \"\"\"Load model checkpoint\"\"\"\n",
        "    start_epoch = 0\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"=> loading checkpoint '{filename}'\")\n",
        "        checkpoint = torch.load(filename)\n",
        "        start_epoch = checkpoint['epochs']\n",
        "        criterion = checkpoint['criterion']\n",
        "        train_acc = checkpoint['train_acc']\n",
        "        train_loss = checkpoint['train_loss']\n",
        "        lr = checkpoint['lr']\n",
        "        test_acc = checkpoint['test_acc']\n",
        "        test_loss = checkpoint['test_loss']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        print(f\"=> loaded checkpoint '{filename}' (epoch {checkpoint['epochs']})\")\n",
        "    else:\n",
        "        print(f\"=> no checkpoint found at '{filename}'\")\n",
        "        train_acc = []\n",
        "        train_loss = []\n",
        "        lr = []\n",
        "        test_acc = []\n",
        "        test_loss = []\n",
        "    return model, optimizer, scheduler, criterion, start_epoch, train_acc, train_loss, lr, test_acc, test_loss\n",
        "\n",
        "class Plotter:\n",
        "    \"\"\"Plotting utilities\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_metrics(train_acc, train_loss, test_acc, test_loss):\n",
        "        \"\"\"Plot training metrics\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Plot accuracy\n",
        "        axes[0].plot(train_acc, label='Train Accuracy', marker='o')\n",
        "        axes[0].plot(test_acc, label='Test Accuracy', marker='s')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Accuracy (%)')\n",
        "        axes[0].set_title('Training and Test Accuracy')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Plot loss\n",
        "        axes[1].plot(train_loss, label='Train Loss', marker='o')\n",
        "        axes[1].plot(test_loss, label='Test Loss', marker='s')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Loss')\n",
        "        axes[1].set_title('Training and Test Loss')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_lr_schedule(epochs, lr_history):\n",
        "        \"\"\"Plot learning rate schedule\"\"\"\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(lr_history)\n",
        "        plt.xlabel('Training Steps')\n",
        "        plt.ylabel('Learning Rate')\n",
        "        plt.title('OneCycleLR Schedule')\n",
        "        plt.grid(True)\n",
        "        plt.yscale('log')\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_images(images_data, classes, title=\"Images\", denormalize=True):\n",
        "        \"\"\"Plot a grid of images\"\"\"\n",
        "        if len(images_data) == 0:\n",
        "            print(\"No images to display\")\n",
        "            return\n",
        "\n",
        "        # Denormalize images\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "        fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
        "        axes = axes.ravel()\n",
        "\n",
        "        for idx, img_data in enumerate(images_data[:20]):\n",
        "            if idx >= 20:\n",
        "                break\n",
        "            img = img_data['image'].numpy().transpose(1, 2, 0)\n",
        "            if denormalize:\n",
        "                img = std * img + mean\n",
        "                img = np.clip(img, 0, 1)\n",
        "\n",
        "            axes[idx].imshow(img)\n",
        "            pred_label = classes[img_data['pred']] if len(classes) > img_data['pred'] else str(img_data['pred'])\n",
        "            true_label = classes[img_data['true']] if len(classes) > img_data['true'] else str(img_data['true'])\n",
        "            axes[idx].set_title(f'Pred: {pred_label}\\nTrue: {true_label}', fontsize=8)\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.suptitle(title, fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"Utility functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjUZd3T47UzX"
      },
      "source": [
        "## Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWNOGRNv7TSv",
        "outputId": "545f229a-2720-491f-f71f-51f2e86e73ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using fixed MAX_LR: 0.01\n",
            "Training for 1 epochs\n",
            "Skipping LR Finder to save time and memory.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Skip LR Finder - Use Fixed Learning Rate\n",
        "# ==============================================================================\n",
        "import gc\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Override EPOCHS to 1\n",
        "EPOCHS = 1\n",
        "\n",
        "# Set maximum learning rate directly\n",
        "MAX_LR = 0.01\n",
        "print(f\"Using fixed MAX_LR: {MAX_LR}\")\n",
        "print(f\"Training for {EPOCHS} epochs\")\n",
        "print(\"Skipping LR Finder to save time and memory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "Qgv6Lue97-k3",
        "outputId": "ae38c4de-c0ef-40e8-ba71-b5647363d4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1 epoch only\n",
            "================================================================================\n",
            "Starting Training with OneCycleLR\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EPOCH: 1/1\n",
            "Learning Rate: 1.00e-03\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/782 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 150.12 MiB is free. Process 2556 has 14.59 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4246837301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtrain_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Test with misclassified and correctly classified images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2174047601.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, device, train_loader, optimizer, criterion, scheduler)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 150.12 MiB is free. Process 2556 has 14.59 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Update EPOCHS to 1\n",
        "# ==============================================================================\n",
        "EPOCHS = 1\n",
        "print(f\"Training for {EPOCHS} epoch only\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Main Training Loop with OneCycleLR\n",
        "# ==============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"Starting Training with OneCycleLR\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Setup OneCycleLR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=MAX_LR,\n",
        "    total_steps=None,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=len(dataloaders['train']),\n",
        "    pct_start=0.3,  # Warmup for 30% of epoch\n",
        "    anneal_strategy='linear',\n",
        "    cycle_momentum=False,\n",
        "    base_momentum=0.9,\n",
        "    max_momentum=0.95,\n",
        "    div_factor=10,\n",
        "    final_div_factor=10\n",
        ")\n",
        "\n",
        "# Initialize training and testing objects\n",
        "train_obj = Trainer()\n",
        "test_obj = Tester()\n",
        "\n",
        "# Training history\n",
        "train_acc = []\n",
        "train_loss = []\n",
        "lr_history = []\n",
        "test_acc = []\n",
        "test_losses = []\n",
        "\n",
        "# Training loop\n",
        "start_time = time.time()\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EPOCH: {epoch}/{EPOCHS}\")\n",
        "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Store learning rate\n",
        "    lr_history.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Train\n",
        "    epoch_start = time.time()\n",
        "    train_obj.train(model, DEVICE, dataloaders['train'], optimizer, criterion, scheduler=scheduler)\n",
        "\n",
        "    # Test with misclassified and correctly classified images\n",
        "    test_obj.test(model, DEVICE, dataloaders['val'], criterion,\n",
        "                 misclassfied_required=True, trueclassified_required=True,\n",
        "                 classes=classes, class_accuracy=90)\n",
        "\n",
        "    # Store metrics\n",
        "    train_acc.append(train_obj.train_acc[-1])\n",
        "    train_loss.append(train_obj.train_losses[-1])\n",
        "    test_acc.append(test_obj.test_acc[-1])\n",
        "    test_losses.append(test_obj.test_losses[-1])\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"\\nEpoch Time: {epoch_time:.2f}s\")\n",
        "    print(f\"Train Acc: {train_acc[-1]:.2f}% | Test Acc: {test_acc[-1]:.2f}%\")\n",
        "\n",
        "    # Save best model\n",
        "    if test_acc[-1] > best_acc:\n",
        "        best_acc = test_acc[-1]\n",
        "        print(f\"✨ New best accuracy: {best_acc:.2f}%\")\n",
        "        save_model(model, optimizer, criterion, scheduler, epoch, train_acc, train_loss,\n",
        "                  lr_history, test_acc, test_losses, 'imagenet200_resnet50_best.pth')\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Training Finished!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Total training time: {total_time/60:.2f} minutes ({total_time/3600:.2f} hours)\")\n",
        "print(f\"Final Training Accuracy: {train_acc[-1]:.2f}%\")\n",
        "print(f\"Final Testing Accuracy: {test_acc[-1]:.2f}%\")\n",
        "print(f\"Best Model saved at: imagenet200_resnet50_best.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zANGhMGDNe2"
      },
      "source": [
        "## Visualization and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqI9iIZzBH1X"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Visualize Training Results\n",
        "# ==============================================================================\n",
        "\n",
        "# Plot training metrics\n",
        "print(\"Plotting training and validation metrics...\")\n",
        "Plotter.plot_metrics(train_acc, train_loss, test_acc, test_losses)\n",
        "\n",
        "# Plot learning rate schedule\n",
        "print(\"\\nPlotting learning rate schedule...\")\n",
        "# For 1 epoch, we need to collect all lr values during training\n",
        "# The lr_history list only has one entry per epoch, so let's just display it\n",
        "print(f\"Learning rate range during training: {min(lr_history) if lr_history else 'N/A':.2e} to {max(lr_history) if lr_history else 'N/A':.2e}\")\n",
        "\n",
        "# Display statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training Summary\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Final Train Accuracy: {train_acc[-1]:.2f}%\")\n",
        "print(f\"Final Test Accuracy: {test_acc[-1]:.2f}%\")\n",
        "print(f\"Final Train Loss: {train_loss[-1]:.4f}\")\n",
        "print(f\"Final Test Loss: {test_losses[-1]:.4f}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==============================================================================\n",
        "# Visualize Misclassified and Correctly Classified Images\n",
        "# ==============================================================================\n",
        "\n",
        "# Get misclassified and correctly classified images from the last epoch\n",
        "misclassified_images = test_obj.misclassified_images\n",
        "correctly_classified_images = test_obj.trueclassified_images\n",
        "\n",
        "print(f\"\\nNumber of misclassified images stored: {len(misclassified_images)}\")\n",
        "print(f\"Number of correctly classified images stored: {len(correctly_classified_images)}\")\n",
        "\n",
        "# Plot misclassified images\n",
        "if len(misclassified_images) > 0:\n",
        "    print(\"\\nPlotting misclassified images...\")\n",
        "    Plotter.plot_images(misclassified_images, classes, title=\"Misclassified Images\", denormalize=True)\n",
        "else:\n",
        "    print(\"\\nNo misclassified images to display\")\n",
        "\n",
        "# Plot correctly classified images\n",
        "if len(correctly_classified_images) > 0:\n",
        "    print(\"\\nPlotting correctly classified images...\")\n",
        "    Plotter.plot_images(correctly_classified_images, classes, title=\"Correctly Classified Images\", denormalize=True)\n",
        "else:\n",
        "    print(\"\\nNo correctly classified images to display\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"All Done! 🎉\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nYour model achieved {test_acc[-1]:.2f}% accuracy on TinyImageNet-200 after 1 epoch!\")\n",
        "print(f\"Model checkpoint saved at: imagenet200_resnet50_best.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Results and Future Work\n",
        "\n",
        "**Current Results:** During this trial run on Google Colab, training for 1 epoch yielded approximately **4% training accuracy** and **8% testing accuracy** on TinyImageNet-200.\n",
        "\n",
        "**Why Only 1 Epoch?** The primary limitation encountered was the instability of Colab's T4 GPU runtime, which frequently disconnected between epochs. This led to kernel restarts and the need to re-run epochs from scratch, making multi-epoch training impractical in this environment.\n",
        "\n",
        "**Why Low Accuracy?** It's important to note that this is merely a **trial/dummy architecture** to establish the training pipeline and workflow. The team and I will collaboratively develop a significantly improved architecture with better hyperparameters, data augmentation strategies, and model configurations in subsequent iterations.\n",
        "\n",
        "**Next Steps:** The final optimized model will be trained on **AWS EC2 instances with adequate GPU resources** (avoiding the runtime disconnection issues faced on Colab), allowing for stable, long-duration training sessions to achieve competitive performance on the ImageNet-1k dataset.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
